{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8aaa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3aeb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000227365C38C0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/wikipedia/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000022736708050>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/wikipedia/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000227367082D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/wikipedia/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000022736708550>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/wikipedia/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000227367087D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/wikipedia/\n",
      "ERROR: Could not find a version that satisfies the requirement wikipedia (from versions: none)\n",
      "ERROR: No matching distribution found for wikipedia\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c1595ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now over here we will be making out a wrapper that can make sure that we can first set up the wrapper around the wikipida with the content taht we want\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "##making the tool setting it up with this wrapper to make sure we use it to interact with the wikipedia\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b47fada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000254FFD21A90>, search_kwargs={})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##this one is the custom tool for this requirement for the webbase loeadr\n",
    "##the above ones are used for the already existing apis\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader= WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs= loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(documents, embeddings)\n",
    "retriever=db.as_retriever()\n",
    "retriever\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f4e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##making a tools that can retrive the info on the langsmith\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\"Search for info about langsmith. for any question about langsmith u must use this tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee219e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "Arxiv_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv= ArxivQueryRun(api_wrapper=Arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc058c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now combining / chaining the above made tools\n",
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9365df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now to use the agents in order to perform the search on this combined tools thing lets make a new llm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f687e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##u can make your own prompt using promttemplate\n",
    "##but over here we will make a new prompt and get that from hub\n",
    "from langchain import hub\n",
    "prompt= hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41e25d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets create the agent in order to perform the retrieval\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "agent=create_openai_functions_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9270c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "##to execute the agent operation we use agent executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer=AgentExecutor(agent=agent,tools=tools,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14cc7a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith is framework agnostic — you can use it with or without LangChain’s open source frameworks langchain and langgraph.\n",
      "\n",
      "LangSmith is framework agnostic — you can use it with or without LangChain’s open source frameworks langchain and langgraph.\n",
      "\n",
      "Get started with LangSmith - Docs by LangChainOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "\n",
      "Get started with LangSmith - Docs by LangChainOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications.  It allows you to monitor and evaluate your application, enabling faster and more confident deployments.  It's framework-agnostic, meaning you can use it with or without LangChain's open-source frameworks.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"LangSmith is a platform for building production-grade LLM applications.  It allows you to monitor and evaluate your application, enabling faster and more confident deployments.  It's framework-agnostic, meaning you can use it with or without LangChain's open-source frameworks.\\n\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
