{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8aaa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3aeb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1595ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now over here we will be making out a wrapper that can make sure that we can first set up the wrapper around the wikipida with the content taht we want\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "##making the tool setting it up with this wrapper to make sure we use it to interact with the wikipedia\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b47fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\ppriy\\AppData\\Local\\Temp\\ipykernel_11472\\3731178355.py:12: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x0000015342010AD0>, search_kwargs={})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##this one is the custom tool for this requirement for the webbase loeadr\n",
    "##the above ones are used for the already existing apis\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader= WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs= loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = Chroma.from_documents(documents, embeddings)\n",
    "retriever=db.as_retriever()\n",
    "retriever\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f4e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##making a tools that can retrive the info on the langsmith\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\"Search for info about langsmith. for any question about langsmith u must use this tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee219e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "Arxiv_wrapper=ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "arxiv= ArxivQueryRun(api_wrapper=Arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc058c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now combining / chaining the above made tools\n",
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9365df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##now to use the agents in order to perform the search on this combined tools thing lets make a new llm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f687e4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##u can make your own prompt using promttemplate\n",
    "##but over here we will make a new prompt and get that from hub\n",
    "from langchain import hub\n",
    "prompt= hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e25d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets create the agent in order to perform the retrieval\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "agent=create_openai_functions_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9270c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "##to execute the agent operation we use agent executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executer=AgentExecutor(agent=agent,tools=tools,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14cc7a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'LangSmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLangSmith is framework agnostic — you can use it with or without LangChain’s open source frameworks langchain and langgraph.\n",
      "\n",
      "Get started with LangSmith - Docs by LangChainOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KLangSmithPlatform for LLM observability and evaluationOverviewQuickstartsTrace an applicationEvaluate an applicationTest promptsAPI & SDKsAPI referencePython SDKJS/TS SDKPricingPlansPricing FAQOur new LangChain Academy course on Deep Agents is now live! Enroll for free.Docs by LangChain home pagePythonSearch...⌘KGitHubForumForumSearch...NavigationGet started with LangSmithGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGet startedObservabilityEvaluationPrompt engineeringSelf-hostingAdministrationGitHubForumGet started with LangSmithCopy pageCopy pageLangSmith is a platform for building production-grade LLM applications. Monitor and evaluate your application, so you can ship quickly and with confidence.\n",
      "\n",
      "Start tracingGain visibility into each step your application takes when handling a request to debug faster.Learn moreEvaluate your applicationMeasure quality of your applications over time to build more reliable AI applications.Learn moreTest your promptsIterate on prompts, with automatic version control and collaboration features.Learn moreSet up your workspaceSet up your workspace, configure admin settings, and invite your team to collaborate.Learn moreWas this page helpful?YesNoTrace an applicationAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith is a platform for building production-grade LLM applications.  It allows you to monitor and evaluate your application to improve reliability and speed up development.  Key features include tracing applications to debug faster, evaluating application quality over time, testing prompts with version control and collaboration, and setting up workspaces for team collaboration.  It's framework-agnostic, meaning you can use it with or without LangChain's open-source frameworks.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"LangSmith is a platform for building production-grade LLM applications.  It allows you to monitor and evaluate your application to improve reliability and speed up development.  Key features include tracing applications to debug faster, evaluating application quality over time, testing prompts with version control and collaboration, and setting up workspaces for team collaboration.  It's framework-agnostic, meaning you can use it with or without LangChain's open-source frameworks.\\n\"}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executer.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
